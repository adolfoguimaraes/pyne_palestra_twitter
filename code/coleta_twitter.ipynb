{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adolfoguimaraes/pyne_palestra_twitter/blob/main/code/coleta_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZXd7uhAviJJ"
      },
      "source": [
        "# Coletando dados do twitter com Python\n",
        "\n",
        "Esse material foi criado para servir de suporte para a palestra **Coletando dados do Twitter com Python** que foi apresentada na Python Nordeste 2022 em Aracaju/SE. \n",
        "\n",
        "## Conteúdo\n",
        "\n",
        "* Slides da Apresentação\n",
        "* A biblioteca Twarc\n",
        "* Métodos básicos de consulta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW_isTAVviJN"
      },
      "source": [
        "### Slides da Apresentação \n",
        "\n",
        "(em breve)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmH0xKmJviJO"
      },
      "source": [
        "### A biblioteca Twarc\n",
        "\n",
        "Esse repositório possui scripts em python para realizar a coleta de tweets utilizando a biblioteca [TWARC](https://twarc-project.readthedocs.io/en/latest/). A biblioteca permite utilizar a versão mais nova da API do Twitter (v2), além de ter acesso aos recursos para quem tem o _Academic Access Research_. A principal escolha dessa biblioteca foi por conta da possibilidade de utilizar o acesso acadêmico, quando o usuário tem essa permissão. \n",
        "\n",
        "A instalação pode ser feita a partir do comando `pip install twarc` e o seu uso pode ser feito a partir da linha de comando com a chamada do comando `twarc` ou por meio de scripts em python. Esse material usa a segunda abordagem.\n",
        "\n",
        "A biblioteca permite acesso a diferentes métodos disponibilizados pela API do twitter. Vamos trabalhar as seguintes opções: \n",
        "\n",
        "* Busca dos tweets recentes a partir de uma string de busca. \n",
        "* Coleta de tweets a partir do métodos de `stream` (busca em tempo real).\n",
        "* Coleta de tweets postados por um usuário.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação das bibliotecas (apenas para quem for rodar direto no colab)\n",
        "\n",
        "!pip install twarc \n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "id": "S4OTFVXBvogM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF1WZFhuviJR"
      },
      "outputs": [],
      "source": [
        "# imports necessários \n",
        "\n",
        "from twarc.expansions import flatten\n",
        "from twarc.client2 import Twarc2\n",
        "import jsonlines\n",
        "import threading\n",
        "import datetime\n",
        "import pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaoGITMoviJS"
      },
      "outputs": [],
      "source": [
        "# Método auxiliar para impressão dos tweets. \n",
        "def print_basic_information(tweet):\n",
        "    print(\"Criado em: %s\" % tweet['created_at'])\n",
        "    print(\"Criado por: %s\" % tweet['author']['username'])\n",
        "    print(\"Texto: %s \" % tweet['text'])\n",
        "    if 'referenced_tweets' in tweet.keys():\n",
        "        print(\"Tweets referenciados:\")\n",
        "        for ref in tweet['referenced_tweets']:\n",
        "            print(\"Tipo: %s\" % ref['type'])\n",
        "            print(\"Texto: %s \" % ref['text'])\n",
        "            print(\"-------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sO5Qm6eviJV"
      },
      "source": [
        "### Acesso à API do Twitter\n",
        "\n",
        "Para executar os scripts é necessário ter uma conta de desenvolvedor no Twitter. O cadastro de desenvolvedor pode ser feito no link: https://developer.twitter.com/. A chave utilizada vai ser o `Bearer Token` que pode ser gerado diretamente no portal de desenvolvedor. Essa chave é necessária para conectar à versão 2.0 da API do Twitter.\n",
        "\n",
        "Alguns acessos só são permitidos para os usuários que têm o _Academic Research Access_. Mais detalhes dos requisitos para solicitar esse tipo de acesso estão disponíveis no link: https://developer.twitter.com/en/products/twitter-api/academic-research. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng378CUIviJX"
      },
      "source": [
        "### Credencias e instância da API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wke6b8wRviJZ"
      },
      "outputs": [],
      "source": [
        "# Credenciais \n",
        "\n",
        "BEARER_TOKEN = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-94IFuYviJZ"
      },
      "outputs": [],
      "source": [
        "# Instanciando a biblioteca \n",
        "\n",
        "api_ = Twarc2(bearer_token=BEARER_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVAtF5ywviJc"
      },
      "source": [
        "### Método `Search`\n",
        "\n",
        "A busca dos tweets recentes podem ser feitas a partir do método `search_recent` que recebe os seguintes parâmetros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWFCr575viJd"
      },
      "outputs": [],
      "source": [
        "# Retorna um conjunto de páginas contendo `max_results` por página.\n",
        "# Existe um limitação a depender do tipo de conta que esteja utilizando \n",
        "# Mas há uma limitação do próprio método que limita há um período de 7 dias.\n",
        "\n",
        "response = api_.search_recent(\"#python\", sort_order='recency', max_results=100)\n",
        "\n",
        "limit_pages = 2\n",
        "count_pages = 1\n",
        "all_tweets = []\n",
        "for page in response:\n",
        "    tweets = flatten(page)\n",
        "    print(\"Tweets coletados na página %i: %i\" % (count_pages, len(tweets)))\n",
        "    all_tweets.extend(tweets)\n",
        "    if count_pages == limit_pages:\n",
        "        break \n",
        "\n",
        "    count_pages += 1\n",
        "\n",
        "print(\"Total coletado: %i\" % len(all_tweets))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhBY5X3tviJe"
      },
      "outputs": [],
      "source": [
        "# Imprimindo algums informações dos tweets coletados\n",
        "print_basic_information(all_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhj0napIviJf"
      },
      "source": [
        "**Salvando as informações em um arquivo:**\n",
        "\n",
        "Ao invés de imprimir o resultado da busca na tela, vamos salvar em um arquivo `.jsonl`. Esse arquivo aceita o mesmo formato do json, com a diferença que cada linha armazena um arquivo json distinto. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFLbTmluviJg"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(\"../output/arquivoteste.jsonl\", mode=\"a\") as writer:\n",
        "    writer.write_all(all_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4LVIvPviJh"
      },
      "source": [
        "## Buscando em um `timeline`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP-aPEKsviJi"
      },
      "outputs": [],
      "source": [
        "response_timeline = api_.timeline(user=\"adolfoguimaraes\", exclude_retweets=True, exclude_replies=True, max_results=10)\n",
        "\n",
        "limit_pages = 2\n",
        "count_pages = 1\n",
        "all_tweets_timeline = []\n",
        "for page in response_timeline:\n",
        "    tweets = flatten(page)\n",
        "    print(\"Tweets coletados na página %i: %i\" % (count_pages, len(tweets)))\n",
        "    all_tweets_timeline.extend(tweets)\n",
        "    if count_pages == limit_pages:\n",
        "        break \n",
        "\n",
        "    count_pages += 1\n",
        "\n",
        "print(\"Total coletado: %i\" % len(all_tweets_timeline))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX7-OaUMviJj"
      },
      "source": [
        "**Salvando dados em um arquivo:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPvJMfJNviJk"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(\"../output/arquivoteste2.jsonl\", mode=\"a\") as writer:\n",
        "    writer.write_all(all_tweets_timeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogfszAfAviJk"
      },
      "source": [
        "## Busca em tempo real (`Stream`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYYwpYeGviJm"
      },
      "outputs": [],
      "source": [
        "# Regras de busca\n",
        "new_rules = [{\"value\": \"#pythonnordeste\", \"tag\": \"pythonnordeste\"}]\n",
        "rules_ = api_.add_stream_rules(new_rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elayYLtzviJm"
      },
      "outputs": [],
      "source": [
        "# Coletando tweets\n",
        "event = threading.Event()\n",
        "\n",
        "limit_ = 5\n",
        "\n",
        "for count, result in enumerate(api_.stream(event=event)):\n",
        "    tweet_ = flatten(result)\n",
        "    for t in tweet_:\n",
        "        print_basic_information(t)\n",
        "\n",
        "    if count >= limit_ - 1:\n",
        "        event.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBUmCQLvviJo"
      },
      "outputs": [],
      "source": [
        "rule_ids = [r[\"id\"] for r in rules_[\"data\"]]\n",
        "api_.delete_stream_rule_ids(rule_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-30-5X4kviJo"
      },
      "outputs": [],
      "source": [
        "api_.get_stream_rules()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGURBUDvviJp"
      },
      "source": [
        "## Busca `Archive`\n",
        "\n",
        "A busca no arquivo do twitter está disponível apenas para quem tem a conta com acesso acadêmico. Ela permite realizar a busca dentro de um período estabelecido desde de 2006. No entanto, esse tipo de busca tem que ser feita com um pouco mais de cuidado porque o número de tweets retornados pode ser muito alto. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQDV_QXhviJp"
      },
      "outputs": [],
      "source": [
        "api_academic = Twarc2(bearer_token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pFeLYp8viJp"
      },
      "outputs": [],
      "source": [
        "start_ = datetime.datetime.strptime(\"2022-08-25 00:00:00\", \"%Y-%m-%d %H:%M:%S\").astimezone(tz=pytz.UTC)\n",
        "end_ = datetime.datetime.strptime(\"2022-08-25 22:00:00\", \"%Y-%m-%d %H:%M:%S\").astimezone(tz=pytz.UTC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjIdQT7uviJr"
      },
      "outputs": [],
      "source": [
        "all_tweets = []\n",
        "for response_page in api_academic.search_all(\"#CartaPorUmGovernoEstadualAberto\", sort_order='recency', max_results=100, start_time=start_, end_time=end_):\n",
        "    tweets = flatten(response_page)\n",
        "    print(\"Tweets coletados: %i \" % len(tweets) )\n",
        "    all_tweets.extend(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZZFyV70viJr"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(\"../output/arquivoteste3.jsonl\", mode=\"a\") as writer:\n",
        "    writer.write_all(all_tweets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('pyne_twitter')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "bbd019ec572e55e35eff1dab8b3cebcb7a7857df89b0472eecc45ee1a080fb53"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}